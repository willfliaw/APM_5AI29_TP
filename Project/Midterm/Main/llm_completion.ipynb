{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:00:48.693963Z",
     "start_time": "2025-01-04T21:00:37.930171Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Respect the import order, otherwise there will be conflicts\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from torch.optim import Adam, AdamW\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory\n",
    "from huggingface_hub import login\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from tqdm import tqdm\n",
    "from transformers.models.paligemma.convert_paligemma_weights_to_hf import device\n",
    "\n",
    "# Read the token from the file\n",
    "with open(\"huggingface_token.txt\", \"r\") as f:\n",
    "    token = f.read().strip()\n",
    "\n",
    "# Authenticate with the token\n",
    "login(token)\n",
    "\n",
    "model_name = \"meta-llama/Llama-3.2-3B\"\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.float16\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=token)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Load the model in 4-bit quantized form for efficiency\n",
    "llama_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    quantization_config=quant_config,\n",
    "    torch_dtype=torch.float16\n",
    ")"
   ],
   "id": "3e8a4391377a486b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-04 22:00:40.883997: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-04 22:00:40.893380: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1736024440.904261  388505 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1736024440.907408  388505 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-01-04 22:00:40.920068: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "loading file tokenizer.json from cache at /home/eddie/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/tokenizer.json\n",
      "loading file tokenizer.model from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/eddie/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/eddie/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/tokenizer_config.json\n",
      "loading file chat_template.jinja from cache at None\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "loading configuration file config.json from cache at /home/eddie/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/config.json\n",
      "Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"meta-llama/Llama-3.2-3B\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"attention_bias\": false,\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"head_dim\": 128,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 8192,\n",
      "  \"max_position_embeddings\": 131072,\n",
      "  \"mlp_bias\": false,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 24,\n",
      "  \"num_hidden_layers\": 28,\n",
      "  \"num_key_value_heads\": 8,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-05,\n",
      "  \"rope_scaling\": {\n",
      "    \"factor\": 32.0,\n",
      "    \"high_freq_factor\": 4.0,\n",
      "    \"low_freq_factor\": 1.0,\n",
      "    \"original_max_position_embeddings\": 8192,\n",
      "    \"rope_type\": \"llama3\"\n",
      "  },\n",
      "  \"rope_theta\": 500000.0,\n",
      "  \"tie_word_embeddings\": true,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.47.1\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 128256\n",
      "}\n",
      "\n",
      "loading weights file model.safetensors from cache at /home/eddie/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/model.safetensors.index.json\n",
      "Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"eos_token_id\": 128001\n",
      "}\n",
      "\n",
      "target_dtype {target_dtype} is replaced by `CustomDtype.INT4` for 4-bit BnB quantization\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33e9367900404298be927c5f21b48d6a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "All the weights of LlamaForCausalLM were initialized from the model checkpoint at meta-llama/Llama-3.2-3B.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "loading configuration file generation_config.json from cache at /home/eddie/.cache/huggingface/hub/models--meta-llama--Llama-3.2-3B/snapshots/13afe5124825b4f3751f836b40dafda64c1ed062/generation_config.json\n",
      "Generate config GenerationConfig {\n",
      "  \"bos_token_id\": 128000,\n",
      "  \"do_sample\": true,\n",
      "  \"eos_token_id\": 128001,\n",
      "  \"temperature\": 0.6,\n",
      "  \"top_p\": 0.9\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:01:08.456162Z",
     "start_time": "2025-01-04T21:00:59.076384Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pykeen.triples import TriplesFactory\n",
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "# Define Neo4j connections\n",
    "host = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"12345678\"\n",
    "driver = GraphDatabase.driver(host, auth=(user, password))\n",
    "\n",
    "def run_query(query, params={}):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, params)\n",
    "        return pd.DataFrame([r.values() for r in result], columns=result.keys())\n",
    "    \n",
    "# Cell 2: Load your graph data\n",
    "data = run_query(\"\"\"\n",
    "    MATCH (s)-[r]->(t)\n",
    "    RETURN toString(s.name) as source, toString(t.name) AS target, type(r) as type\n",
    "\"\"\")\n",
    "tf = TriplesFactory.from_labeled_triples(\n",
    "    data[[\"source\", \"type\", \"target\"]].values, compact_id=False\n",
    ")\n",
    "\n",
    "# tf,_ = tf.split([0.05, 0.95])\n",
    "\n",
    "training, testing, validation = tf.split([0.8, 0.1, 0.1])\n",
    "print(f\"Training samples: {training.num_triples}\")"
   ],
   "id": "245de215f35e4b4d",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using automatically assigned random_state=1210578443\n",
      "using automatically assigned random_state=1057842493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22468\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:40:31.875974Z",
     "start_time": "2025-01-04T21:40:31.868219Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import shelve\n",
    "from functools import lru_cache\n",
    "import os\n",
    "\n",
    "CACHE_FILE = \"wikidata_cache.db\"\n",
    "\n",
    "def fetch_from_wikidata(name):\n",
    "    \"\"\"\n",
    "    Fetch data from Wikidata API for the given name.\n",
    "    \"\"\"\n",
    "    url = \"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"format\": \"json\",\n",
    "        \"language\": \"en\",\n",
    "        \"search\": name\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        search_results = data.get(\"search\", [])\n",
    "        if search_results:\n",
    "            best_result = search_results[0]\n",
    "            label = best_result.get(\"label\", \"Unknown\")\n",
    "            description = best_result.get(\"description\", \"No description available\")\n",
    "            entity_id = best_result.get(\"id\", \"Unknown ID\")\n",
    "            return f\"{label} ({entity_id}): {description}\"\n",
    "    print(f\"Failed for {name}: {response.status_code}\")\n",
    "    return \"No results found.\"\n",
    "\n",
    "@lru_cache(maxsize=2048)\n",
    "def cached_wikidata_entry(name):\n",
    "    \"\"\"\n",
    "    Check the persistent cache or fetch and cache the result.\n",
    "    \"\"\"\n",
    "    # Check the persistent cache first\n",
    "    with shelve.open(CACHE_FILE) as cache:\n",
    "        if name in cache:\n",
    "            return cache[name]\n",
    "\n",
    "    # Fetch from Wikidata if not in the persistent cache\n",
    "    result = fetch_from_wikidata(name)\n",
    "\n",
    "    # Save to persistent cache\n",
    "    with shelve.open(CACHE_FILE, writeback=True) as cache:\n",
    "        cache[name] = result\n",
    "\n",
    "    return result\n",
    "\n",
    "def clear_persistent_cache():\n",
    "    \"\"\"\n",
    "    Clear the persistent cache.\n",
    "    \"\"\"\n",
    "    if os.path.exists(CACHE_FILE):\n",
    "        os.remove(CACHE_FILE)"
   ],
   "id": "b7eff3dcb564e68b",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:37:41.281080Z",
     "start_time": "2025-01-04T21:37:41.265480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "with shelve.open(CACHE_FILE) as cache:\n",
    "    df = pd.DataFrame(cache.items())\n",
    "df"
   ],
   "id": "e3bc1065ce12e06c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             0  \\\n",
       "0    regulates   \n",
       "1       A4GALT   \n",
       "2        ABCC4   \n",
       "3       AARSD1   \n",
       "4        A2ML1   \n",
       "..         ...   \n",
       "169       AARS   \n",
       "170     ABCA12   \n",
       "171      ABCC6   \n",
       "172      ABCF2   \n",
       "173      ABTB2   \n",
       "\n",
       "                                                                                                                 1  \n",
       "0    Regulates synthesis of L1 and L11 SDY_3744 (Q27474466): microbial protein found in Shigella dysenteriae Sd197  \n",
       "1                                              A4GALT (Q18040751): protein-coding gene in the species Homo sapiens  \n",
       "2                                               ABCC4 (Q14913379): protein-coding gene in the species Homo sapiens  \n",
       "3                                              AARSD1 (Q18046762): protein-coding gene in the species Homo sapiens  \n",
       "4                                               A2ML1 (Q18051234): protein-coding gene in the species Homo sapiens  \n",
       "..                                                                                                             ...  \n",
       "169                                                                                  Aars (Q17378638): family name  \n",
       "170                                            ABCA12 (Q14881706): protein-coding gene in the species Homo sapiens  \n",
       "171                                             ABCC6 (Q14916171): protein-coding gene in the species Homo sapiens  \n",
       "172                                             ABCF2 (Q18034994): protein-coding gene in the species Homo sapiens  \n",
       "173                                             ABTB2 (Q18037736): protein-coding gene in the species Homo sapiens  \n",
       "\n",
       "[174 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>regulates</td>\n",
       "      <td>Regulates synthesis of L1 and L11 SDY_3744 (Q27474466): microbial protein found in Shigella dysenteriae Sd197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A4GALT</td>\n",
       "      <td>A4GALT (Q18040751): protein-coding gene in the species Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABCC4</td>\n",
       "      <td>ABCC4 (Q14913379): protein-coding gene in the species Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AARSD1</td>\n",
       "      <td>AARSD1 (Q18046762): protein-coding gene in the species Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A2ML1</td>\n",
       "      <td>A2ML1 (Q18051234): protein-coding gene in the species Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>AARS</td>\n",
       "      <td>Aars (Q17378638): family name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>ABCA12</td>\n",
       "      <td>ABCA12 (Q14881706): protein-coding gene in the species Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>ABCC6</td>\n",
       "      <td>ABCC6 (Q14916171): protein-coding gene in the species Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>ABCF2</td>\n",
       "      <td>ABCF2 (Q18034994): protein-coding gene in the species Homo sapiens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>ABTB2</td>\n",
       "      <td>ABTB2 (Q18037736): protein-coding gene in the species Homo sapiens</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:09:21.825724Z",
     "start_time": "2025-01-04T21:09:21.806263Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.empty_cache()",
   "id": "84cd1a7affd6b809",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:58:35.289755Z",
     "start_time": "2025-01-04T21:55:29.613864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Dict\n",
    "import torch\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "def precompute_embeddings(\n",
    "    model: PreTrainedModel,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    labels: Dict[int, str],\n",
    "    max_length: int = 128,\n",
    "    batch_size: int = 32\n",
    ") -> torch.Tensor:\n",
    "    # Initialize a tensor to store the embeddings\n",
    "    embeddings = torch.zeros(len(labels), model.config.hidden_size, dtype=torch.float32, device=model.device)\n",
    "    \n",
    "    # Create a list of labels to process in batches\n",
    "    label_list = list(labels.values())\n",
    "    # Use RAG embeddings\n",
    "    label_list = [cached_wikidata_entry(label) for label in tqdm(label_list, desc=\"Getting Wikidata Entries\")]\n",
    "    num_batches = len(label_list) // batch_size + (1 if len(label_list) % batch_size > 0 else 0)\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        # Get a batch of labels\n",
    "        batch_labels = label_list[i * batch_size: (i + 1) * batch_size]\n",
    "        \n",
    "        # Tokenize all labels in the batch\n",
    "        inputs = tokenizer(batch_labels, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_length)\n",
    "        inputs = {key: value.to(model.device) for key, value in inputs.items()}  # Move to device\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs, output_hidden_states=True)\n",
    "            hidden_states = outputs.hidden_states[-1]  # Get last hidden state (size: [batch_size, seq_len, hidden_size])\n",
    "\n",
    "            # Use the [CLS]-like token embedding (first token) for each label\n",
    "            embeddings_batch = hidden_states[:, 0, :].to(dtype=torch.float32)  # Shape: [batch_size, hidden_size]\n",
    "\n",
    "            # Store the embeddings in the correct indices\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, len(labels))\n",
    "            embeddings[start_idx:end_idx] = embeddings_batch\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "relation_llama_embeddings = precompute_embeddings(llama_model, tokenizer, tf.relation_id_to_label)\n",
    "entity_llama_embeddings = precompute_embeddings(llama_model, tokenizer, tf.entity_id_to_label)"
   ],
   "id": "53d4476f92d944a8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 1/1 [00:00<00:00, 11.65it/s]\n",
      "Processing batches: 100%|██████████| 156/156 [03:05<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Destroy embeddings\n",
    "xavier_uniform_(relation_llama_embeddings)\n",
    "xavier_uniform_(entity_llama_embeddings)"
   ],
   "id": "9f8fab6f81e5aefc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\"\"\"\n",
    "* Working llama embedding pipeline\n",
    "\"\"\"\n",
    "\n",
    "from pykeen.evaluation import RankBasedEvaluator\n",
    "from pykeen.nn.init import init_phases, xavier_uniform_\n",
    "from pykeen.nn.modules import FunctionalInteraction\n",
    "from pykeen.models import ERModel\n",
    "from pykeen.nn.representation import Embedding\n",
    "from pykeen.nn.init import xavier_uniform_\n",
    "from pykeen.utils import negative_norm\n",
    "\n",
    "class LLamaEntityRepresentation(Embedding):\n",
    "    \"\"\"Entity representation that combines complex RotatE embeddings with dummy embeddings.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_id: int,\n",
    "        embedding_dim: int,\n",
    "        llama_dim: int,\n",
    "        llama_embeddings: torch.Tensor,\n",
    "        initializer=xavier_uniform_,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Initialize complex embeddings for RotatE\n",
    "        super().__init__(\n",
    "            max_id=max_id,\n",
    "            shape=embedding_dim,\n",
    "            initializer=initializer,\n",
    "            dtype=torch.cfloat,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        self.llama_projection = torch.nn.Linear(\n",
    "            in_features=llama_model.config.hidden_size,\n",
    "            out_features=llama_dim,\n",
    "            bias=True\n",
    "        )\n",
    "        self.llama_embeddings = nn.Embedding.from_pretrained(llama_embeddings, freeze=True)\n",
    "\n",
    "    def _plain_forward(self, indices=None):\n",
    "        # Get complex RotatE embeddings\n",
    "        rotate_embeddings = super()._plain_forward(indices)\n",
    "        \n",
    "        # Handle case when indices are None (return all embeddings)\n",
    "        if indices is None:\n",
    "            llama__embeddings = self.llama_embeddings.weight\n",
    "        else:\n",
    "            llama__embeddings = self.llama_embeddings(indices)\n",
    "        \n",
    "        llama_projection = self.llama_projection(llama__embeddings)\n",
    "        llama_projection = torch.nn.functional.normalize(llama_projection, p=2, dim=-1)\n",
    "        \n",
    "        # print(f\"Embeddings: {llama_projection.shape}, {indices is None}, {indices.shape if indices is not None else None}\")\n",
    "        return rotate_embeddings, llama_projection\n",
    "\n",
    "class RotatEDummyInteraction(FunctionalInteraction):\n",
    "    \"\"\"Extended RotatE interaction that handles both complex and dummy embeddings.\"\"\"\n",
    "    \n",
    "    def forward(self, h, r, t):\n",
    "        # Unpack complex and dummy parts\n",
    "        h_complex, h_dummy = h\n",
    "        t_complex, t_dummy = t\n",
    "        r_complex, r_dummy = r\n",
    "        \n",
    "        # Regular RotatE score with complex embeddings\n",
    "        if h_complex.dim() == 3 and r_complex.dim() == 3 and t_complex.dim() == 3:\n",
    "            h_complex = h_complex.expand(r_complex.shape[0], -1, -1)\n",
    "            t_complex = t_complex.expand(r_complex.shape[0], -1, -1)\n",
    "            \n",
    "        # Compute RotatE interaction in complex space\n",
    "        rotated_h = h_complex * r_complex\n",
    "        rotate_score = negative_norm(rotated_h - t_complex, p=2, power_norm=False)\n",
    "        \n",
    "        # print(f\"pre: h_dummy: {h_dummy.shape}, r_dummy: {r_dummy.shape}, t_dummy: {t_dummy.shape}\")\n",
    "        # Handle dummy embeddings with simple multiplication\n",
    "        if h_dummy.dim() == 3 and r_dummy.dim() == 3 and t_dummy.dim() == 3:\n",
    "            h_dummy = h_dummy.expand(r_dummy.shape[0], -1, -1)\n",
    "            t_dummy = t_dummy.expand(r_dummy.shape[0], -1, -1)\n",
    "        \n",
    "        # print(f\"pos: h_dummy: {h_dummy.shape}, r_dummy: {r_dummy.shape}, t_dummy: {t_dummy.shape}\")\n",
    "        dummy_score = (h_dummy * r_dummy * t_dummy).sum(dim=-1)\n",
    "        \n",
    "        # Combine scores\n",
    "        return rotate_score + dummy_score\n",
    "\n",
    "class RotatEWithDummy(ERModel):\n",
    "    \"\"\"RotatE model extended with dummy embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_entities: int,\n",
    "        num_relations: int,\n",
    "        embedding_dim: int = 200,\n",
    "        llama_dim: int = 50,\n",
    "        entity_initializer=xavier_uniform_,\n",
    "        relation_initializer=init_phases,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Initialize entity representations (both complex and dummy)\n",
    "        entity_representations = LLamaEntityRepresentation(\n",
    "            max_id=num_entities,\n",
    "            embedding_dim=embedding_dim,\n",
    "            llama_dim=llama_dim,\n",
    "            llama_embeddings = entity_llama_embeddings,\n",
    "            initializer=entity_initializer,\n",
    "        )\n",
    "        \n",
    "        # Initialize relation representations (both complex and dummy)\n",
    "        relation_representations = LLamaEntityRepresentation(\n",
    "            max_id=num_relations,\n",
    "            embedding_dim=embedding_dim,\n",
    "            llama_dim=llama_dim,\n",
    "            llama_embeddings = relation_llama_embeddings,\n",
    "            initializer=relation_initializer,\n",
    "        )\n",
    "        \n",
    "        # Initialize the model with custom interaction\n",
    "        super().__init__(\n",
    "            entity_representations=entity_representations,\n",
    "            relation_representations=relation_representations,\n",
    "            interaction=RotatEDummyInteraction,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "# Pipeline usage\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    validation=validation,\n",
    "    model=RotatEWithDummy,\n",
    "    model_kwargs={\n",
    "        'num_entities': tf.num_entities,\n",
    "        'num_relations': tf.num_relations,\n",
    "        'embedding_dim': 128,  # Complex embedding dimension\n",
    "        'llama_dim': 32,\n",
    "    },\n",
    "    optimizer='adam',\n",
    "    stopper='early',\n",
    "    epochs=100,\n",
    "    random_seed=42,\n",
    ")\n",
    "result.plot_losses()\n",
    "evaluator = RankBasedEvaluator()\n",
    "# Evaluate the model\n",
    "metrics = evaluator.evaluate(\n",
    "    result.model,\n",
    "    testing.mapped_triples,\n",
    "    additional_filter_triples=[training.mapped_triples, validation.mapped_triples],\n",
    ")\n",
    "# Print the metrics\n",
    "print(f\"Hits@1: {metrics.get_metric('hits@1')}\")\n",
    "print(f\"Hits@3: {metrics.get_metric('hits@3')}\")\n",
    "print(f\"Hits@5: {metrics.get_metric('hits@5')}\")\n",
    "print(f\"Hits@10: {metrics.get_metric('hits@10')}\")\n",
    "print(f\"Mean Rank: {metrics.get_metric('mean_rank')}\")\n",
    "print(f\"Mean Reciprocal Rank: {metrics.get_metric('mean_reciprocal_rank')}\")"
   ],
   "id": "b5c484a9f8d5e7fc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T22:17:33.051273Z",
     "start_time": "2025-01-04T22:15:50.700436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result.losses\n",
    "\"\"\"\n",
    "* Baseline\n",
    "\"\"\"\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    training_kwargs= {\n",
    "        'batch_size': 1024\n",
    "    },\n",
    "    testing=testing,\n",
    "    validation=validation,\n",
    "    model=\"RotatE\",\n",
    "    stopper=\"early\",\n",
    "    epochs=100,\n",
    "    dimensions=128,\n",
    "    random_seed=420,\n",
    "    device='cuda',\n",
    ")\n",
    "result.plot_losses()\n",
    "\n",
    "evaluator = RankBasedEvaluator()\n",
    "# Evaluate the model\n",
    "metrics = evaluator.evaluate(\n",
    "    result.model,\n",
    "    testing.mapped_triples,\n",
    "    additional_filter_triples=[training.mapped_triples, validation.mapped_triples],\n",
    ")\n",
    "# Print the metrics\n",
    "print(f\"Hits@1: {metrics.get_metric('hits@1')}\")\n",
    "print(f\"Hits@3: {metrics.get_metric('hits@3')}\")\n",
    "print(f\"Hits@5: {metrics.get_metric('hits@5')}\")\n",
    "print(f\"Hits@10: {metrics.get_metric('hits@10')}\")\n",
    "print(f\"Mean Rank: {metrics.get_metric('mean_rank')}\")\n",
    "print(f\"Mean Reciprocal Rank: {metrics.get_metric('mean_reciprocal_rank')}\")"
   ],
   "id": "a9b96474dac3218e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "INFO:pykeen.stoppers.early_stopping:Inferred checkpoint path for best model weights: /home/eddie/.data/pykeen/checkpoints/best-model-weights-79e877ca-358f-46e2-89ac-10e1eaed2faf.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/100 [00:00<?, ?epoch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "adda080ef4b14aa8a2ccc7c3800d83c2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1c78eab1ef444ecab50f96256680db68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34cee78bea4d471699bf308fa02c5ae1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2252674bbd6a4a9b8a671a22376ad8f0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "371eebc06be94fc3ab3c3bd6149a019b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ac65eb6f9a804c1abeb7ea90d3b1bdcf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "12ef973b5dc64eb8a4e5e5758385e360"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d914b7f82fe4895af146d021f69fda3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "eddb39ecba1646a4a64cd499f87c1725"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b0abf3a8d36f4a5dab7ac3054b1bab4b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8d7d1b00905f4fd597f6ae50766ce78e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 8.98s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 10: 0.010501957992168031. Saved model weights to /home/eddie/.data/pykeen/checkpoints/best-model-weights-79e877ca-358f-46e2-89ac-10e1eaed2faf.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0eb72a2d401f48ca8fbf777cf35467b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "471b6a95a93449b1a8295a8e5eb8b988"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1a687971f8e34af68fe83e8cb95d5df3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b352545a2b924adf838f71a757e5e6b7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d67e88d4bbb14a979b668d1c4243a8c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "075d38375f184cd28e1f79ea2484a301"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e7651e371044c9198f5ac1c0c0f4832"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6992eff3fbb64070abe771ebfe6746ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b33e58704b4244dc80e8e9c745caeeb4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "021f8a5dffc34222aafef9ea4fa5084b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 7.26s seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6a7c0f3c16b245c9bd6923aca26ab9d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7f4bcca022e14ef5a2b8567d5dc61fed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1e4dca45cb384bffb7a4cf8a9a0c952e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5fe6cb51e9a14cb19e693922380234ef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6fa23a99e1b940c189488177cb795b83"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b95580021114401ba7a8460ac7eabebf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b15a521315b46c2a82e8f16e8710864"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b469eb8fe7ba40969f9a3fbabf91025f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "15e74cc6e9d14fae88cb6d132b4a567a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "209bd419e1434eb49e47390f1d3629b5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 5.85s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:Stopping early at epoch 30. The best result 0.010501957992168031 occurred at epoch 10.\n",
      "INFO:pykeen.stoppers.early_stopping:Re-loading weights from best epoch from /home/eddie/.data/pykeen/checkpoints/best-model-weights-79e877ca-358f-46e2-89ac-10e1eaed2faf.pt\n",
      "/home/eddie/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/pykeen/stoppers/early_stopping.py:268: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.model.load_state_dict(torch.load(self.best_model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/2.81k [00:00<?, ?triple/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87899894a8864262adf63ec45814f840"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 9.29s seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/2.81k [00:00<?, ?triple/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a53d35940141462381a7e6a967d1c161"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 7.85s seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits@1: 0.002670940170940171\n",
      "Hits@3: 0.006588319088319089\n",
      "Hits@5: 0.008903133903133903\n",
      "Hits@10: 0.012464387464387465\n",
      "Mean Rank: 6105.05419921875\n",
      "Mean Reciprocal Rank: 0.006822538562119008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:02:26.967072499Z",
     "start_time": "2025-01-04T20:30:54.805493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "result.losses\n",
    "\"\"\"\n",
    "* Working dummy embedding pipeline\n",
    "\"\"\"\n",
    "\n",
    "from pykeen.models import ERModel\n",
    "import torch\n",
    "from pykeen.nn.representation import Embedding\n",
    "from pykeen.nn.init import init_phases, xavier_uniform_\n",
    "from pykeen.nn.modules import FunctionalInteraction\n",
    "from pykeen.utils import negative_norm, ensure_complex\n",
    "\n",
    "class RotatEDummyEntityRepresentation(Embedding):\n",
    "    \"\"\"Entity representation that combines complex RotatE embeddings with dummy embeddings.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_entities: int,\n",
    "        embedding_dim: int,\n",
    "        dummy_dim: int,\n",
    "        initializer=xavier_uniform_,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Initialize complex embeddings for RotatE\n",
    "        super().__init__(\n",
    "            max_id=num_entities,\n",
    "            shape=embedding_dim,\n",
    "            initializer=initializer,\n",
    "            dtype=torch.cfloat,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # Initialize additional dummy embeddings (real-valued)\n",
    "        self.dummy_embeddings = torch.nn.Embedding(num_entities, dummy_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.dummy_embeddings.weight)\n",
    "\n",
    "    def _plain_forward(self, indices=None):\n",
    "        # Get complex RotatE embeddings\n",
    "        rotate_embeddings = super()._plain_forward(indices)\n",
    "        \n",
    "        if indices is None:\n",
    "            dummy_embeddings = self.dummy_embeddings.weight\n",
    "        else:\n",
    "            dummy_embeddings = self.dummy_embeddings(indices.to(self.device))\n",
    "        \n",
    "        print(f\"Embeddings: {dummy_embeddings.shape}, {indices is None}, {indices.shape if indices is not None else None}\")\n",
    "        return rotate_embeddings, dummy_embeddings\n",
    "\n",
    "class RotatEDummyInteraction(FunctionalInteraction):\n",
    "    \"\"\"Extended RotatE interaction that handles both complex and dummy embeddings.\"\"\"\n",
    "    \n",
    "    def forward(self, h, r, t):\n",
    "        # Unpack complex and dummy parts\n",
    "        h_complex, h_dummy = h\n",
    "        t_complex, t_dummy = t\n",
    "        r_complex, r_dummy = r\n",
    "        \n",
    "        # Regular RotatE score with complex embeddings\n",
    "        if h_complex.dim() == 3 and r_complex.dim() == 3 and t_complex.dim() == 3:\n",
    "            h_complex = h_complex.expand(r_complex.shape[0], -1, -1)\n",
    "            t_complex = t_complex.expand(r_complex.shape[0], -1, -1)\n",
    "            \n",
    "        # Compute RotatE interaction in complex space\n",
    "        rotated_h = h_complex * r_complex\n",
    "        rotate_score = negative_norm(rotated_h - t_complex, p=2, power_norm=False)\n",
    "        \n",
    "        print(f\"pre: h_dummy: {h_dummy.shape}, r_dummy: {r_dummy.shape}, t_dummy: {t_dummy.shape}\")\n",
    "        # Handle dummy embeddings with simple multiplication\n",
    "        if h_dummy.dim() == 3 and r_dummy.dim() == 3 and t_dummy.dim() == 3:\n",
    "            h_dummy = h_dummy.expand(r_dummy.shape[0], -1, -1)\n",
    "            t_dummy = t_dummy.expand(r_dummy.shape[0], -1, -1)\n",
    "        \n",
    "        print(f\"pos: h_dummy: {h_dummy.shape}, r_dummy: {r_dummy.shape}, t_dummy: {t_dummy.shape}\")\n",
    "        dummy_score = (h_dummy * r_dummy * t_dummy).sum(dim=-1)\n",
    "        \n",
    "        # Combine scores\n",
    "        return rotate_score + dummy_score\n",
    "\n",
    "class RotatEWithDummy(ERModel):\n",
    "    \"\"\"RotatE model extended with dummy embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_entities: int,\n",
    "        num_relations: int,\n",
    "        embedding_dim: int = 200,\n",
    "        dummy_dim: int = 50,\n",
    "        entity_initializer=xavier_uniform_,\n",
    "        relation_initializer=init_phases,\n",
    "        **kwargs\n",
    "    ):\n",
    "        # Initialize entity representations (both complex and dummy)\n",
    "        entity_representations = LLamaEntityRepresentation(\n",
    "            num_entities=num_entities,\n",
    "            embedding_dim=embedding_dim,\n",
    "            dummy_dim=dummy_dim,\n",
    "            initializer=entity_initializer\n",
    "        )\n",
    "        \n",
    "        # Initialize relation representations (both complex and dummy)\n",
    "        relation_representations = LLamaEntityRepresentation(\n",
    "            num_entities=num_relations,\n",
    "            embedding_dim=embedding_dim,\n",
    "            dummy_dim=dummy_dim,\n",
    "            initializer=relation_initializer\n",
    "        )\n",
    "        \n",
    "        # Initialize the model with custom interaction\n",
    "        super().__init__(\n",
    "            entity_representations=entity_representations,\n",
    "            relation_representations=relation_representations,\n",
    "            interaction=RotatEDummyInteraction,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "# Pipeline usage\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    validation=validation,\n",
    "    model=RotatEWithDummy,\n",
    "    model_kwargs={\n",
    "        'num_entities': tf.num_entities,\n",
    "        'num_relations': tf.num_relations,\n",
    "        'embedding_dim': 128,  # Complex embedding dimension\n",
    "        'dummy_dim': 32,      # Dummy embedding dimension\n",
    "    },\n",
    "    optimizer='adam',\n",
    "    stopper='early',\n",
    "    epochs=1,\n",
    "    random_seed=42,\n",
    ")\n",
    "result.plot_losses()"
   ],
   "id": "39610dfcc8d0191b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "INFO:pykeen.stoppers.early_stopping:Inferred checkpoint path for best model weights: /home/eddie/.data/pykeen/checkpoints/best-model-weights-0555768f-6ec2-4073-9b19-2101b78ee9c3.pt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/1 [00:00<?, ?epoch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1fa2c37230964806883fa823ea8c2071"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/88 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "044d22715f1943438ccdc54d940508d9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "Embeddings: torch.Size([256, 32]), False, torch.Size([256])\n",
      "pre: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "pos: h_dummy: torch.Size([256, 32]), r_dummy: torch.Size([256, 32]), t_dummy: torch.Size([256, 32])\n",
      "Embeddings: torch.Size([196, 32]), False, torch.Size([196])\n",
      "Embeddings: torch.Size([196, 32]), False, torch.Size([196])\n",
      "Embeddings: torch.Size([196, 32]), False, torch.Size([196])\n",
      "pre: h_dummy: torch.Size([196, 32]), r_dummy: torch.Size([196, 32]), t_dummy: torch.Size([196, 32])\n",
      "pos: h_dummy: torch.Size([196, 32]), r_dummy: torch.Size([196, 32]), t_dummy: torch.Size([196, 32])\n",
      "Embeddings: torch.Size([196, 32]), False, torch.Size([196])\n",
      "Embeddings: torch.Size([196, 32]), False, torch.Size([196])\n",
      "Embeddings: torch.Size([196, 32]), False, torch.Size([196])\n",
      "pre: h_dummy: torch.Size([196, 32]), r_dummy: torch.Size([196, 32]), t_dummy: torch.Size([196, 32])\n",
      "pos: h_dummy: torch.Size([196, 32]), r_dummy: torch.Size([196, 32]), t_dummy: torch.Size([196, 32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/2.81k [00:00<?, ?triple/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad8a0e4d35e7426e998f3cd0abb1ffb3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: torch.Size([19930, 32]), True, None\n",
      "Embeddings: torch.Size([2808, 1, 32]), False, torch.Size([2808, 1])\n",
      "Embeddings: torch.Size([2808, 1, 32]), False, torch.Size([2808, 1])\n",
      "Embeddings: torch.Size([19930, 32]), True, None\n",
      "Embeddings: torch.Size([1376, 1, 32]), False, torch.Size([1376, 1])\n",
      "Embeddings: torch.Size([1376, 1, 32]), False, torch.Size([1376, 1])\n",
      "Embeddings: torch.Size([19930, 32]), True, None\n",
      "Embeddings: torch.Size([672, 1, 32]), False, torch.Size([672, 1])\n",
      "Embeddings: torch.Size([672, 1, 32]), False, torch.Size([672, 1])\n",
      "Embeddings: torch.Size([19930, 32]), True, None\n",
      "Embeddings: torch.Size([320, 1, 32]), False, torch.Size([320, 1])\n",
      "Embeddings: torch.Size([320, 1, 32]), False, torch.Size([320, 1])\n",
      "Embeddings: torch.Size([19930, 32]), True, None\n",
      "Embeddings: torch.Size([160, 1, 32]), False, torch.Size([160, 1])\n",
      "Embeddings: torch.Size([160, 1, 32]), False, torch.Size([160, 1])\n",
      "Embeddings: torch.Size([19930, 32]), True, None\n",
      "Embeddings: torch.Size([64, 1, 32]), False, torch.Size([64, 1])\n",
      "Embeddings: torch.Size([64, 1, 32]), False, torch.Size([64, 1])\n",
      "Embeddings: torch.Size([19930, 32]), True, None\n",
      "Embeddings: torch.Size([32, 1, 32]), False, torch.Size([32, 1])\n",
      "Embeddings: torch.Size([32, 1, 32]), False, torch.Size([32, 1])\n",
      "pre: h_dummy: torch.Size([1, 19930, 32]), r_dummy: torch.Size([32, 1, 32]), t_dummy: torch.Size([32, 1, 32])\n",
      "pos: h_dummy: torch.Size([32, 19930, 32]), r_dummy: torch.Size([32, 1, 32]), t_dummy: torch.Size([32, 1, 32])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 116\u001B[0m\n\u001B[1;32m    108\u001B[0m         \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\n\u001B[1;32m    109\u001B[0m             entity_representations\u001B[38;5;241m=\u001B[39mentity_representations,\n\u001B[1;32m    110\u001B[0m             relation_representations\u001B[38;5;241m=\u001B[39mrelation_representations,\n\u001B[1;32m    111\u001B[0m             interaction\u001B[38;5;241m=\u001B[39mRotatEDummyInteraction,\n\u001B[1;32m    112\u001B[0m             \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[1;32m    113\u001B[0m         )\n\u001B[1;32m    115\u001B[0m \u001B[38;5;66;03m# Pipeline usage\u001B[39;00m\n\u001B[0;32m--> 116\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[43mpipeline\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    117\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtesting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtesting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mRotatEWithDummy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnum_entities\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_entities\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    123\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mnum_relations\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_relations\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    124\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43membedding_dim\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Complex embedding dimension\u001B[39;49;00m\n\u001B[1;32m    125\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdummy_dim\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m      \u001B[49m\u001B[38;5;66;43;03m# Dummy embedding dimension\u001B[39;49;00m\n\u001B[1;32m    126\u001B[0m \u001B[43m    \u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43madam\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstopper\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mearly\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    129\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    130\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrandom_seed\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m42\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    131\u001B[0m \u001B[43m)\u001B[49m\n\u001B[1;32m    132\u001B[0m result\u001B[38;5;241m.\u001B[39mplot_losses()\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/pykeen/pipeline/api.py:1556\u001B[0m, in \u001B[0;36mpipeline\u001B[0;34m(dataset, dataset_kwargs, training, testing, validation, evaluation_entity_whitelist, evaluation_relation_whitelist, model, model_kwargs, interaction, interaction_kwargs, dimensions, loss, loss_kwargs, regularizer, regularizer_kwargs, optimizer, optimizer_kwargs, clear_optimizer, lr_scheduler, lr_scheduler_kwargs, training_loop, training_loop_kwargs, negative_sampler, negative_sampler_kwargs, epochs, training_kwargs, stopper, stopper_kwargs, evaluator, evaluator_kwargs, evaluation_kwargs, result_tracker, result_tracker_kwargs, metadata, device, random_seed, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001B[0m\n\u001B[1;32m   1533\u001B[0m evaluator_instance, evaluation_kwargs \u001B[38;5;241m=\u001B[39m _handle_evaluator(\n\u001B[1;32m   1534\u001B[0m     _result_tracker\u001B[38;5;241m=\u001B[39m_result_tracker,\n\u001B[1;32m   1535\u001B[0m     evaluator\u001B[38;5;241m=\u001B[39mevaluator,\n\u001B[1;32m   1536\u001B[0m     evaluator_kwargs\u001B[38;5;241m=\u001B[39mevaluator_kwargs,\n\u001B[1;32m   1537\u001B[0m     evaluation_kwargs\u001B[38;5;241m=\u001B[39mevaluation_kwargs,\n\u001B[1;32m   1538\u001B[0m )\n\u001B[1;32m   1540\u001B[0m stopper_instance, configuration, losses, train_seconds \u001B[38;5;241m=\u001B[39m _handle_training(\n\u001B[1;32m   1541\u001B[0m     _result_tracker\u001B[38;5;241m=\u001B[39m_result_tracker,\n\u001B[1;32m   1542\u001B[0m     training\u001B[38;5;241m=\u001B[39mtraining,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1553\u001B[0m     use_tqdm\u001B[38;5;241m=\u001B[39muse_tqdm,\n\u001B[1;32m   1554\u001B[0m )\n\u001B[0;32m-> 1556\u001B[0m metric_results, evaluate_seconds \u001B[38;5;241m=\u001B[39m \u001B[43m_handle_evaluation\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1557\u001B[0m \u001B[43m    \u001B[49m\u001B[43m_result_tracker\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_result_tracker\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1558\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_instance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1559\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevaluator_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluator_instance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1560\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstopper_instance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstopper_instance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1561\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1562\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtesting\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtesting\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1563\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidation\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1564\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtraining_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtraining_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1565\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevaluation_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluation_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1566\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_testing_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_testing_data\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1567\u001B[0m \u001B[43m    \u001B[49m\u001B[43mevaluation_fallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluation_fallback\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1568\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfilter_validation_when_testing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfilter_validation_when_testing\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1569\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_tqdm\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_tqdm\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1570\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1571\u001B[0m _result_tracker\u001B[38;5;241m.\u001B[39mend_run()\n\u001B[1;32m   1573\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m PipelineResult(\n\u001B[1;32m   1574\u001B[0m     random_seed\u001B[38;5;241m=\u001B[39m_random_seed,\n\u001B[1;32m   1575\u001B[0m     model\u001B[38;5;241m=\u001B[39mmodel_instance,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1584\u001B[0m     evaluate_seconds\u001B[38;5;241m=\u001B[39mevaluate_seconds,\n\u001B[1;32m   1585\u001B[0m )\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/pykeen/pipeline/api.py:1284\u001B[0m, in \u001B[0;36m_handle_evaluation\u001B[0;34m(_result_tracker, model_instance, evaluator_instance, stopper_instance, training, testing, validation, training_kwargs, evaluation_kwargs, use_testing_data, evaluation_fallback, filter_validation_when_testing, use_tqdm)\u001B[0m\n\u001B[1;32m   1275\u001B[0m _result_tracker\u001B[38;5;241m.\u001B[39mlog_params(\n\u001B[1;32m   1276\u001B[0m     params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mdict\u001B[39m(\n\u001B[1;32m   1277\u001B[0m         evaluation_kwargs\u001B[38;5;241m=\u001B[39m{\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1281\u001B[0m     )\n\u001B[1;32m   1282\u001B[0m )\n\u001B[1;32m   1283\u001B[0m evaluate_start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m-> 1284\u001B[0m metric_results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluator_instance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1285\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_instance\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmapped_triples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmapped_triples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mevaluation_kwargs\u001B[49m\n\u001B[1;32m   1286\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1287\u001B[0m evaluate_end_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m evaluate_start_time\n\u001B[1;32m   1288\u001B[0m step \u001B[38;5;241m=\u001B[39m training_kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_epochs\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/pykeen/evaluation/evaluator.py:311\u001B[0m, in \u001B[0;36mEvaluator.evaluate\u001B[0;34m(self, model, mapped_triples, batch_size, slice_size, device, use_tqdm, tqdm_kwargs, restrict_entities_to, restrict_relations_to, do_time_consuming_checks, additional_filter_triples, pre_filtered_triples, targets)\u001B[0m\n\u001B[1;32m    309\u001B[0m     tqdm_kwargs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdisable\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    310\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 311\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_evaluate_on_device\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmapped_triples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmapped_triples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m        \u001B[49m\u001B[43mslice_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mslice_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdevice\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m        \u001B[49m\u001B[43mall_pos_triples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_pos_triples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrestrict_entities_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrestrict_entities_to\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtargets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtqdm_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtqdm_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    321\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    322\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mMemoryError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[1;32m    323\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m device\u001B[38;5;241m.\u001B[39mtype \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/pykeen/evaluation/evaluator.py:388\u001B[0m, in \u001B[0;36mEvaluator._evaluate_on_device\u001B[0;34m(self, model, mapped_triples, batch_size, slice_size, device, all_pos_triples, targets, tqdm_kwargs, **kwargs)\u001B[0m\n\u001B[1;32m    376\u001B[0m \u001B[38;5;66;03m# Show progressbar\u001B[39;00m\n\u001B[1;32m    377\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tqdm(\n\u001B[1;32m    378\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mChainMap(\n\u001B[1;32m    379\u001B[0m         \u001B[38;5;28mdict\u001B[39m(tqdm_kwargs),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    386\u001B[0m     )\n\u001B[1;32m    387\u001B[0m ) \u001B[38;5;28;01mas\u001B[39;00m progress_bar:\n\u001B[0;32m--> 388\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mevaluate\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    389\u001B[0m \u001B[43m        \u001B[49m\u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    390\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmapped_triples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmapped_triples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# note: we provide the *maximum* batch and slice size here; it is reduced if necessary\u001B[39;49;00m\n\u001B[1;32m    392\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    393\u001B[0m \u001B[43m        \u001B[49m\u001B[43mslice_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mslice_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    394\u001B[0m \u001B[43m        \u001B[49m\u001B[43mprogress_bar\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprogress_bar\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    395\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtargets\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    396\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# kwargs\u001B[39;49;00m\n\u001B[1;32m    397\u001B[0m \u001B[43m        \u001B[49m\u001B[43mall_pos_triples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_pos_triples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    398\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    399\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    400\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    401\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/torch_max_mem/api.py:511\u001B[0m, in \u001B[0;36mMemoryUtilizationMaximizer.__call__.<locals>.inner\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    509\u001B[0m     values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtuple\u001B[39m(bound\u001B[38;5;241m.\u001B[39marguments[name] \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameter_names)\n\u001B[1;32m    510\u001B[0m kwargs\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameter_names, values))\n\u001B[0;32m--> 511\u001B[0m result, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparameter_value[h] \u001B[38;5;241m=\u001B[39m \u001B[43mwrapped\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/torch_max_mem/api.py:368\u001B[0m, in \u001B[0;36mmaximize_memory_utilization_decorator.<locals>.decorator_maximize_memory_utilization.<locals>.wrapper_maximize_memory_utilization\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    366\u001B[0m bound_arguments\u001B[38;5;241m.\u001B[39marguments\u001B[38;5;241m.\u001B[39mupdate(p_kwargs)\n\u001B[1;32m    367\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 368\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbound_arguments\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mbound_arguments\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mtuple\u001B[39m(\n\u001B[1;32m    369\u001B[0m         max_values\n\u001B[1;32m    370\u001B[0m     )\n\u001B[1;32m    371\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mOutOfMemoryError, \u001B[38;5;167;01mRuntimeError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m error:\n\u001B[1;32m    372\u001B[0m     \u001B[38;5;66;03m# raise errors unrelated to out-of-memory\u001B[39;00m\n\u001B[1;32m    373\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_oom_error(error):\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib64/python3.12/site-packages/torch/utils/_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[1;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[0;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/pykeen/evaluation/evaluator.py:514\u001B[0m, in \u001B[0;36mevaluate\u001B[0;34m(evaluator, mapped_triples, batch_size, slice_size, progress_bar, targets, **kwargs)\u001B[0m\n\u001B[1;32m    512\u001B[0m relation_filter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    513\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m target \u001B[38;5;129;01min\u001B[39;00m targets:\n\u001B[0;32m--> 514\u001B[0m     relation_filter \u001B[38;5;241m=\u001B[39m \u001B[43m_evaluate_batch\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    516\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    517\u001B[0m \u001B[43m        \u001B[49m\u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mevaluator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrelation_filter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrelation_filter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    519\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    520\u001B[0m \u001B[43m        \u001B[49m\u001B[43mslice_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mslice_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    521\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    522\u001B[0m \u001B[38;5;66;03m# update progress bar with actual batch size\u001B[39;00m\n\u001B[1;32m    523\u001B[0m progress_bar\u001B[38;5;241m.\u001B[39mupdate(batch\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m])\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/pykeen/evaluation/evaluator.py:679\u001B[0m, in \u001B[0;36m_evaluate_batch\u001B[0;34m(batch, model, target, evaluator, slice_size, all_pos_triples, relation_filter, restrict_entities_to, mode)\u001B[0m\n\u001B[1;32m    673\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    674\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIf filtering_necessary of positive_masks_required is True, all_pos_triples has to be \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    675\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mprovided, but is None.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    676\u001B[0m         )\n\u001B[1;32m    678\u001B[0m     \u001B[38;5;66;03m# Create filter\u001B[39;00m\n\u001B[0;32m--> 679\u001B[0m     positive_filter, relation_filter \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_sparse_positive_filter_\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    680\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhrt_batch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[43m        \u001B[49m\u001B[43mall_pos_triples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mall_pos_triples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    682\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrelation_filter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrelation_filter\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    683\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfilter_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcolumn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    684\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    685\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    686\u001B[0m     positive_filter \u001B[38;5;241m=\u001B[39m relation_filter \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/Nextcloud/2024ws/tda_51056/venv/lib/python3.12/site-packages/pykeen/evaluation/evaluator.py:574\u001B[0m, in \u001B[0;36mcreate_sparse_positive_filter_\u001B[0;34m(hrt_batch, all_pos_triples, relation_filter, filter_col)\u001B[0m\n\u001B[1;32m    571\u001B[0m entities \u001B[38;5;241m=\u001B[39m hrt_batch[:, other_col : other_col \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    573\u001B[0m entity_filter_test \u001B[38;5;241m=\u001B[39m (all_pos_triples[:, other_col : other_col \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m])\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;241m==\u001B[39m entities\n\u001B[0;32m--> 574\u001B[0m filter_batch \u001B[38;5;241m=\u001B[39m \u001B[43m(\u001B[49m\u001B[43mentity_filter_test\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m&\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mrelation_filter\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnonzero\u001B[49m\u001B[43m(\u001B[49m\u001B[43mas_tuple\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    575\u001B[0m filter_batch[:, \u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m=\u001B[39m all_pos_triples[:, filter_col : filter_col \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m)[:, filter_batch[:, \u001B[38;5;241m1\u001B[39m]]\n\u001B[1;32m    577\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m filter_batch, relation_filter\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "* Nonworking llama embedding 1\n",
    "\"\"\"\n",
    "from pykeen.models import ERModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pykeen.nn.representation import Embedding\n",
    "from pykeen.nn.init import xavier_uniform_\n",
    "from pykeen.nn.modules import Interaction\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "from typing import Optional, Union, Dict\n",
    "from torch import FloatTensor, LongTensor\n",
    "\n",
    "class LLaMAEntityRepresentation(Embedding):\n",
    "    \"\"\"Entity representation that concatenates regular embeddings with LLaMA embeddings.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_id: int,\n",
    "        embedding_dim: int,\n",
    "        llama_dim: int,\n",
    "        llama_model: PreTrainedModel,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        # Ensure kwargs has the correct dtype\n",
    "        kwargs['dtype'] = torch.float32\n",
    "        \n",
    "        # Initialize regular embeddings for entities\n",
    "        super().__init__(max_id=max_id, embedding_dim=embedding_dim, **kwargs)\n",
    "\n",
    "        # Initialize LLaMA components with explicit dtype\n",
    "        self.llama_projection = nn.Linear(\n",
    "            in_features=llama_model.config.hidden_size,\n",
    "            out_features=llama_dim,\n",
    "            bias=True\n",
    "        )\n",
    "        # Explicitly move weights to float32\n",
    "        self.llama_projection.weight.data = self.llama_projection.weight.data.to(torch.float32)\n",
    "        if self.llama_projection.bias is not None:\n",
    "            self.llama_projection.bias.data = self.llama_projection.bias.data.to(torch.float32)\n",
    "        \n",
    "        self.llama = llama_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.llama_cache: Dict[int, FloatTensor] = {}\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        \"\"\"Reset the parameters of the model.\"\"\"\n",
    "        super().reset_parameters()\n",
    "        # Explicitly initialize projection layer parameters\n",
    "        nn.init.xavier_uniform_(self.llama_projection.weight.data)\n",
    "        if self.llama_projection.bias is not None:\n",
    "            nn.init.zeros_(self.llama_projection.bias.data)\n",
    "\n",
    "    def _plain_forward(self, indices: Optional[LongTensor] = None) -> FloatTensor:\n",
    "        \"\"\"Get regular and LLaMA embeddings for the given indices.\"\"\"\n",
    "        # Get regular embeddings using the super class's _plain_forward method\n",
    "        regular_embeddings = super()._plain_forward(indices)\n",
    "\n",
    "        if indices is None:\n",
    "            # Return all embeddings\n",
    "            indices = torch.arange(self.max_id, device=self.device)\n",
    "        \n",
    "        # Process entity descriptions through LLaMA\n",
    "        indices_cpu = indices.cpu().tolist()\n",
    "        uncached = [idx for idx in indices_cpu if idx not in self.llama_cache]\n",
    "        \n",
    "        if uncached:\n",
    "            # Get descriptions for uncached entities\n",
    "            texts = [cached_wikidata_entry(f\"Entity_{idx}\") for idx in uncached]\n",
    "            \n",
    "            # Process through LLaMA\n",
    "            inputs = self.tokenizer(\n",
    "                texts,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=True,\n",
    "                truncation=True,\n",
    "                max_length=512\n",
    "            ).to(self.llama.device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                outputs = self.llama(**inputs)\n",
    "                embeddings = outputs.last_hidden_state[:, 0, :].to(dtype=torch.float32)\n",
    "                projected = self.llama_projection(embeddings)\n",
    "                \n",
    "                for idx, emb in zip(uncached, projected):\n",
    "                    self.llama_cache[idx] = emb.to(self.device)\n",
    "        \n",
    "        # Get all embeddings from cache\n",
    "        llama_embeddings = torch.stack([\n",
    "            self.llama_cache[idx] for idx in indices_cpu\n",
    "        ]).to(self.device).to(torch.float32)  # Ensure float32\n",
    "        \n",
    "        # Concatenate regular and LLaMA embeddings\n",
    "        return torch.cat([regular_embeddings, llama_embeddings], dim=-1)\n",
    "\n",
    "class LLaMAEmbeddingInteraction(Interaction):\n",
    "    \"\"\"Interaction function for the combined embeddings.\"\"\"\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        h: FloatTensor,\n",
    "        r: FloatTensor,\n",
    "        t: FloatTensor\n",
    "    ) -> FloatTensor:\n",
    "        # Ensure all inputs are float32\n",
    "        h = h.to(torch.float32)\n",
    "        r = r.to(torch.float32)\n",
    "        t = t.to(torch.float32)\n",
    "        \n",
    "        # Adjust for evaluation\n",
    "        if h.dim() == 3 and r.dim() == 3 and t.dim() == 3:\n",
    "            h = h.expand(r.shape[0], -1, -1)\n",
    "            t = t.expand(r.shape[0], -1, -1)\n",
    "        \n",
    "        # Compute scores\n",
    "        return (h * r * t).sum(dim=-1)\n",
    "\n",
    "class LLaMAEnhancedModel(ERModel):\n",
    "    \"\"\"Model that integrates LLaMA embeddings into entity representations.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_entities: int,\n",
    "        num_relations: int,\n",
    "        embedding_dim: int = 128,\n",
    "        llama_dim: int = 32,\n",
    "        llama_model: PreTrainedModel = None,\n",
    "        tokenizer: PreTrainedTokenizer = None,\n",
    "        **kwargs\n",
    "    ) -> None:\n",
    "        # Initialize the entity representation\n",
    "        entity_representations = LLaMAEntityRepresentation(\n",
    "            max_id=num_entities,\n",
    "            embedding_dim=embedding_dim,\n",
    "            llama_dim=llama_dim,\n",
    "            llama_model=llama_model,\n",
    "            tokenizer=tokenizer,\n",
    "            dtype=torch.float32  # Explicitly set dtype\n",
    "        )\n",
    "        \n",
    "        # Define the interaction function\n",
    "        interaction = LLaMAEmbeddingInteraction()\n",
    "        \n",
    "        # Pass everything to the parent ERModel with explicit dtype\n",
    "        super().__init__(\n",
    "            entity_representations=entity_representations,\n",
    "            relation_representations=Embedding,\n",
    "            relation_representations_kwargs=dict(\n",
    "                embedding_dim=embedding_dim + llama_dim,\n",
    "                dtype=torch.float32  # Explicitly set dtype\n",
    "            ),\n",
    "            interaction=interaction,\n",
    "            **kwargs\n",
    "        )"
   ],
   "id": "36adcc3efed069c1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:02:26.967277823Z",
     "start_time": "2025-01-04T14:02:10.273367Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "* Working dummy embedding pipeline backup\n",
    "\"\"\"\n",
    "import torch\n",
    "from pykeen.models import ERModel\n",
    "from pykeen.nn import Embedding\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.datasets import Nations\n",
    "from pykeen.nn import Interaction\n",
    "\n",
    "\n",
    "class DummyEntityRepresentation(Embedding):\n",
    "    \"\"\"Custom entity representation that concatenates dummy embeddings.\"\"\"\n",
    "\n",
    "    def __init__(self, num_entities, embedding_dim, dummy_dim, **kwargs):\n",
    "        # Initialize regular embeddings for entities\n",
    "        super().__init__(max_id=num_entities, embedding_dim=embedding_dim, **kwargs)\n",
    "\n",
    "        # Initialize dummy embeddings for entities\n",
    "        self.dummy_embeddings = torch.nn.Embedding(num_entities, dummy_dim)\n",
    "        torch.nn.init.xavier_uniform_(self.dummy_embeddings.weight)\n",
    "\n",
    "    def _plain_forward(self, indices=None):\n",
    "        \"\"\"\n",
    "        Get regular and dummy embeddings for the given indices.\n",
    "\n",
    "        Handles the case where indices are None, meaning all embeddings are returned.\n",
    "        \"\"\"\n",
    "        # Get regular embeddings using the super class's _plain_forward method\n",
    "        regular_embeddings = super()._plain_forward(indices)\n",
    "\n",
    "        if indices is None:\n",
    "            # Return all dummy embeddings when indices are None\n",
    "            dummy_embeddings = self.dummy_embeddings.weight\n",
    "        else:\n",
    "            # Lookup specific dummy embeddings\n",
    "            dummy_embeddings = self.dummy_embeddings(indices.to(self.device))\n",
    "        \n",
    "        # Concatenate regular and dummy embeddings along the last dimension\n",
    "        return torch.cat([regular_embeddings, dummy_embeddings], dim=-1)\n",
    "\n",
    "class DummyEmbeddingInteraction(Interaction):\n",
    "    def forward(self, h, r, t):\n",
    "        \n",
    "        # Adjust for evaluation\n",
    "        if h.dim() == 3 and r.dim() == 3 and t.dim() == 3:\n",
    "            # Broadcasting adjustments:\n",
    "            # Expand h to match the first dimension of r (batch size or total triples)\n",
    "            h = h.expand(r.shape[0], -1, -1)\n",
    "            # Expand t similarly to match r\n",
    "            t = t.expand(r.shape[0], -1, -1)\n",
    "        \n",
    "        # Ensure embedding dimensions match\n",
    "        if h.size(-1) != r.size(-1) or t.size(-1) != r.size(-1):\n",
    "            raise ValueError(f\"Mismatch in embedding dimensions: \"\n",
    "                             f\"h={h.size(-1)}, r={r.size(-1)}, t={t.size(-1)}\")\n",
    "        \n",
    "        # Compute scores\n",
    "        return (h * r * t).sum(dim=-1)\n",
    "\n",
    "class DummyEmbeddingModel(ERModel):\n",
    "    \"\"\"Custom model that integrates dummy embeddings into the entity representations.\"\"\"\n",
    "    \n",
    "    def __init__(self, num_entities, num_relations, embedding_dim=50, dummy_dim=50, **kwargs):\n",
    "        # Initialize the custom entity representation\n",
    "        entity_representations = DummyEntityRepresentation(\n",
    "            num_entities=num_entities,\n",
    "            embedding_dim=embedding_dim,\n",
    "            dummy_dim=dummy_dim\n",
    "        )\n",
    "        \n",
    "        # Define the custom interaction function\n",
    "        interaction = DummyEmbeddingInteraction()\n",
    "        \n",
    "        # Pass everything to the parent ERModel\n",
    "        super().__init__(\n",
    "            entity_representations=entity_representations,\n",
    "            relation_representations=Embedding,\n",
    "            relation_representations_kwargs=dict(embedding_dim=embedding_dim + dummy_dim),  # Adjust relation embedding size\n",
    "            interaction=interaction,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "\n",
    "result = pipeline(\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    validation=validation,\n",
    "    model=DummyEmbeddingModel,\n",
    "    model_kwargs={\n",
    "        'num_entities': tf.num_entities,\n",
    "        'num_relations': tf.num_relations,\n",
    "        'embedding_dim': 128,  # Regular embedding size\n",
    "        'dummy_dim': 32,  # Dummy embedding size\n",
    "    },\n",
    "    optimizer='adam',\n",
    "    stopper='early',\n",
    "    epochs=10,\n",
    "    random_seed=42,\n",
    ")\n",
    "result.plot_losses()"
   ],
   "id": "26b2fc473889a9ea",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.pipeline.api:Using device: None\n",
      "INFO:pykeen.stoppers.early_stopping:Inferred checkpoint path for best model weights: /home/eddie/.data/pykeen/checkpoints/best-model-weights-87c65e05-dd02-4d35-9797-50166f6a1288.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Training epochs on cuda:0:   0%|          | 0/10 [00:00<?, ?epoch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "52a379b0cfa84760845e0754aac6496f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14caab66238e44dc96aec596da98aa68"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d29d39f3505d4546bddfff603b370339"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f7009ded013947e985f7a26191c6621d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "45f23b84ccfe48e8a5a0c521044ae5ec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ad3555e5b0d54698bf4e28b93b8a36da"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ca39a7d6edb452e8c0fabf43720f272"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ebaef6639d0f4e939e487b74e4518610"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "140f34f4ce104293aaa506a9706d86b9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3efbc26b23cd4d70bc389db2b9b12184"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Training batches on cuda:0:   0%|          | 0/1756 [00:00<?, ?batch/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c92e795cae844f3186f262ad460c9273"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 91.71s seconds\n",
      "INFO:pykeen.stoppers.early_stopping:New best result at epoch 10: 0.0019226660969878231. Saved model weights to /home/eddie/.data/pykeen/checkpoints/best-model-weights-87c65e05-dd02-4d35-9797-50166f6a1288.pt\n",
      "INFO:pykeen.training.training_loop:=> Saved checkpoint after having finished epoch 10.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Evaluating on cuda:0:   0%|          | 0.00/56.2k [00:00<?, ?triple/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bdf352771474752841b6d1b36b0c184"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pykeen.evaluation.evaluator:Evaluation took 97.25s seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Losses Plot'}, xlabel='Epoch', ylabel='marginranking Loss'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:02:26.967389273Z",
     "start_time": "2025-01-04T14:07:25.806618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "* Exemplary RAG pipeline\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Function to retrieve and process external context\n",
    "def get_rag_embedding(entity_name):\n",
    "    \"\"\"\n",
    "    Retrieve and encode Wikidata context for an entity.\n",
    "    \"\"\"\n",
    "    # Retrieve Wikidata context\n",
    "    if check_wikidata_entry(entity_name, print_results=False):\n",
    "        # Example text (replace with actual retrieved Wikidata info)\n",
    "        context = f\"Information about {entity_name} retrieved from Wikidata.\"\n",
    "    else:\n",
    "        context = f\"No Wikidata context found for {entity_name}.\"\n",
    "\n",
    "    # Tokenize and encode the context using Llama\n",
    "    inputs = tokenizer(context, return_tensors=\"pt\", truncation=True).to(model.device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, output_hidden_states=True)\n",
    "    \n",
    "    # Use the last hidden state as the embedding\n",
    "    rag_embedding = outputs.hidden_states[-1].mean(dim=1).squeeze().cpu().numpy()\n",
    "    return rag_embedding\n",
    "\n",
    "def generate_augmented_embeddings(triples_factory):\n",
    "    \"\"\"\n",
    "    Generate embeddings combining Hetionet and RAG features using extracted triples.\n",
    "    \"\"\"\n",
    "    augmented_embeddings = []\n",
    "    triples = triples_factory.mapped_triples  # Extract triples as tensor [num_triples, 3]\n",
    "    for triple in tqdm(triples, desc=\"Generating augmented embeddings\"):\n",
    "        head, relation, tail = triple.tolist()  # Convert tensor to list for indexing\n",
    "        \n",
    "        # Get entity labels for head and tail\n",
    "        head_label = triples_factory.entity_to_id[head]\n",
    "        tail_label = triples_factory.entity_to_id[tail]\n",
    "        \n",
    "        # Generate embeddings\n",
    "        head_emb = get_rag_embedding(head_label)\n",
    "        tail_emb = get_rag_embedding(tail_label)\n",
    "        \n",
    "        # Concatenate embeddings\n",
    "        combined_emb = np.concatenate([head_emb, tail_emb])\n",
    "        augmented_embeddings.append(combined_emb)\n",
    "    \n",
    "    return np.array(augmented_embeddings)\n",
    "\n",
    "# Example: Process training data\n",
    "training_augmented_embeddings = generate_augmented_embeddings(training)\n",
    "\n",
    "# Use augmented embeddings in your model pipeline\n",
    "result = pipeline(\n",
    "    training=training_augmented_embeddings,\n",
    "    testing=testing,  # Similarly process testing and validation\n",
    "    validation=validation,\n",
    "    model=\"RotatE\",  # Use RotatE or any other model\n",
    "    stopper=\"early\",\n",
    "    epochs=4,\n",
    "    dimensions=256,  # Adjust dimensions to match combined embeddings\n",
    "    random_seed=420,\n",
    ")\n",
    "result.plot_losses()"
   ],
   "id": "4ba34fe209e32db5",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 49\u001B[0m\n\u001B[1;32m     46\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray(augmented_embeddings)\n\u001B[1;32m     48\u001B[0m \u001B[38;5;66;03m# Example: Process training data\u001B[39;00m\n\u001B[0;32m---> 49\u001B[0m training_augmented_embeddings \u001B[38;5;241m=\u001B[39m \u001B[43mgenerate_augmented_embeddings\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     51\u001B[0m \u001B[38;5;66;03m# Use augmented embeddings in your model pipeline\u001B[39;00m\n\u001B[1;32m     52\u001B[0m result \u001B[38;5;241m=\u001B[39m pipeline(\n\u001B[1;32m     53\u001B[0m     training\u001B[38;5;241m=\u001B[39mtraining_augmented_embeddings,\n\u001B[1;32m     54\u001B[0m     testing\u001B[38;5;241m=\u001B[39mtesting,  \u001B[38;5;66;03m# Similarly process testing and validation\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     60\u001B[0m     random_seed\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m420\u001B[39m,\n\u001B[1;32m     61\u001B[0m )\n",
      "Cell \u001B[0;32mIn[6], line 31\u001B[0m, in \u001B[0;36mgenerate_augmented_embeddings\u001B[0;34m(triples_factory)\u001B[0m\n\u001B[1;32m     29\u001B[0m augmented_embeddings \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     30\u001B[0m triples \u001B[38;5;241m=\u001B[39m triples_factory\u001B[38;5;241m.\u001B[39mmapped_triples  \u001B[38;5;66;03m# Extract triples as tensor [num_triples, 3]\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m triple \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtqdm\u001B[49m(triples, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mGenerating augmented embeddings\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     32\u001B[0m     head, relation, tail \u001B[38;5;241m=\u001B[39m triple\u001B[38;5;241m.\u001B[39mtolist()  \u001B[38;5;66;03m# Convert tensor to list for indexing\u001B[39;00m\n\u001B[1;32m     34\u001B[0m     \u001B[38;5;66;03m# Get entity labels for head and tail\u001B[39;00m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "* Nonworking llama pipeline 2\n",
    "\"\"\"\n",
    "\n",
    "from typing import Optional\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from pykeen.models import ERModel\n",
    "from pykeen.nn import Embedding, Interaction\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer\n",
    "\n",
    "class LLaMaEnhancedInteraction(Interaction):\n",
    "    def __init__(\n",
    "        self,\n",
    "        llama_model: PreTrainedModel,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        embedding_dim: int = 256\n",
    "    ):\n",
    "        print(\"Starting Interaction initialization\")\n",
    "        super().__init__()\n",
    "        \n",
    "        self.llama = llama_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        # Explicitly set dtype for linear layers\n",
    "        self.llama_projection = nn.Linear(\n",
    "            self.llama.config.hidden_size,\n",
    "            embedding_dim,\n",
    "        ).to(dtype=torch.float32)\n",
    "        \n",
    "        self.combine_layer = nn.Linear(\n",
    "            embedding_dim * 2,\n",
    "            embedding_dim,\n",
    "        ).to(dtype=torch.float32)\n",
    "\n",
    "    def forward(self, h: torch.FloatTensor, r: torch.FloatTensor, t: torch.FloatTensor) -> torch.FloatTensor:\n",
    "        # Convert entity IDs to text descriptions\n",
    "        h_ids = torch.arange(len(h), device=h.device)\n",
    "        t_ids = torch.arange(len(t), device=t.device)\n",
    "        \n",
    "        # Get LLaMA embeddings and convert to float32\n",
    "        h_llama = self._get_llama_embeddings(h_ids).to(dtype=torch.float32)\n",
    "        t_llama = self._get_llama_embeddings(t_ids).to(dtype=torch.float32)\n",
    "        \n",
    "        # Ensure all tensors are float32\n",
    "        h = h.to(dtype=torch.float32)\n",
    "        r = r.to(dtype=torch.float32)\n",
    "        t = t.to(dtype=torch.float32)\n",
    "        \n",
    "        # Combine embeddings\n",
    "        h_combined = self.combine_layer(torch.cat([h, h_llama], dim=-1))\n",
    "        t_combined = self.combine_layer(torch.cat([t, t_llama], dim=-1))\n",
    "        \n",
    "        # Calculate similarity scores\n",
    "        return torch.sum((h_combined + r) * t_combined, dim=-1)\n",
    "\n",
    "    def _get_llama_embeddings(self, ids: torch.Tensor) -> torch.Tensor:\n",
    "        texts = [f\"Entity {ent.item()}\" for ent in ids]\n",
    "        inputs = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        inputs = {k: v.to(self.llama.device) for k, v in inputs.items()}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.llama(**inputs)\n",
    "            # Convert from float16 to float32\n",
    "            embeddings = outputs.last_hidden_state[:, 0, :].to(dtype=torch.float32)\n",
    "        \n",
    "        return self.llama_projection(embeddings)\n",
    "\n",
    "class LLaMaEnhancedKGEModel(ERModel):\n",
    "    def __init__(\n",
    "        self,\n",
    "        llama_model: PreTrainedModel,\n",
    "        tokenizer: PreTrainedTokenizer,\n",
    "        embedding_dim: int = 256,\n",
    "        **kwargs,\n",
    "    ) -> None:\n",
    "        print(\"Starting model initialization\")\n",
    "        \n",
    "        # Ensure we're working with the right precision\n",
    "        self.embedding_dim = embedding_dim\n",
    "        \n",
    "        super().__init__(\n",
    "            interaction=LLaMaEnhancedInteraction,\n",
    "            interaction_kwargs=dict(\n",
    "                llama_model=llama_model,\n",
    "                tokenizer=tokenizer,\n",
    "                embedding_dim=embedding_dim,\n",
    "            ),\n",
    "            entity_representations=Embedding,\n",
    "            entity_representations_kwargs=dict(\n",
    "                shape=(embedding_dim,),  # Note: shape must be a tuple\n",
    "                initializer='xavier_uniform',\n",
    "            ),\n",
    "            relation_representations=Embedding,\n",
    "            relation_representations_kwargs=dict(\n",
    "                shape=(embedding_dim,),  # Note: shape must be a tuple\n",
    "                initializer='xavier_uniform',\n",
    "            ),\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "def create_enhanced_pipeline(\n",
    "    training,\n",
    "    testing,\n",
    "    validation,\n",
    "    llama_model: PreTrainedModel,\n",
    "    tokenizer: PreTrainedTokenizer,\n",
    "    embedding_dim: int = 256,\n",
    ") -> 'PipelineResult':\n",
    "    \"\"\"Create an enhanced pipeline combining LLaMA and PyKEEN models.\"\"\"\n",
    "    # Ensure LLaMA is on correct device\n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    llama_model = llama_model.to(device)\n",
    "    \n",
    "    # Create and run pipeline\n",
    "    result = pipeline(\n",
    "        training=training,\n",
    "        testing=testing,\n",
    "        validation=validation,\n",
    "        model=LLaMaEnhancedKGEModel,\n",
    "        model_kwargs={\n",
    "            'llama_model': llama_model,\n",
    "            'tokenizer': tokenizer,\n",
    "            'embedding_dim': embedding_dim,\n",
    "        },\n",
    "        optimizer='adam',\n",
    "        optimizer_kwargs={'lr': 0.001},\n",
    "        loss='marginranking',\n",
    "        training_kwargs={\n",
    "            'num_epochs': 1, \n",
    "            'batch_size': 128,\n",
    "        },\n",
    "        negative_sampler='basic',\n",
    "        evaluator='rankbased',\n",
    "        evaluator_kwargs={'batch_size': 128},\n",
    "        stopper='early',\n",
    "        stopper_kwargs={\n",
    "            'frequency': 5, \n",
    "            'patience': 2,\n",
    "        },\n",
    "        device=device,\n",
    "    )\n",
    "    \n",
    "    return result"
   ],
   "id": "8fd1cede2316fc13"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-04T21:02:26.967584770Z",
     "start_time": "2025-01-04T14:40:56.985628Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "* Wikidata Analysis Pipeline\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "\n",
    "def check_wikidata_entry(name, print_results=True):\n",
    "    \"\"\"\n",
    "    Check if a given name has a corresponding Wikidata entry and optionally print the results.\n",
    "    \"\"\"\n",
    "    url = f\"https://www.wikidata.org/w/api.php\"\n",
    "    params = {\n",
    "        \"action\": \"wbsearchentities\",\n",
    "        \"format\": \"json\",\n",
    "        \"language\": \"en\",\n",
    "        \"search\": name\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            search_results = data.get(\"search\", [])\n",
    "            if print_results:\n",
    "                print(f\"Results for '{name}':\")\n",
    "                for result in search_results:\n",
    "                    print(f\" - Label: {result.get('label')}, Description: {result.get('description')}, ID: {result.get('id')}\")\n",
    "            return len(search_results) > 0  # True if at least one match found\n",
    "    except Exception as e:\n",
    "        print(f\"Error checking {name}: {e}\")\n",
    "    return False\n",
    "\n",
    "def calculate_match_percentage(names):\n",
    "    \"\"\"\n",
    "    Calculate the percentage of names found in Wikidata.\n",
    "    \"\"\"\n",
    "    unique_names = set(names)  # Ensure uniqueness\n",
    "    matches = [check_wikidata_entry(name) for name in tqdm(unique_names, desc=\"Checking Wikidata\")]\n",
    "\n",
    "    found_count = sum(matches)\n",
    "    total_count = len(unique_names)\n",
    "    percentage_found = (found_count / total_count) * 100 if total_count > 0 else 0\n",
    "\n",
    "    return found_count, total_count, percentage_found\n",
    "\n",
    "# Assuming `data[\"source\"]` is the pandas Series with the names\n",
    "\n",
    "# Extract names as a list\n",
    "names = data[\"source\"].dropna().tolist()  # Drop any NaN values for safety\n",
    "\n",
    "# Calculate match statistics\n",
    "found_count, total_count, percentage_found = calculate_match_percentage(names)\n",
    "\n",
    "# Print results\n",
    "print(f\"Checked {total_count} unique entities.\")\n",
    "print(f\"Found Wikidata entries for {found_count} entities.\")\n",
    "print(f\"Percentage found: {percentage_found:.2f}%\")"
   ],
   "id": "9671eaa3dfebdb74",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tqdm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 47\u001B[0m\n\u001B[1;32m     44\u001B[0m names \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msource\u001B[39m\u001B[38;5;124m\"\u001B[39m]\u001B[38;5;241m.\u001B[39mdropna()\u001B[38;5;241m.\u001B[39mtolist()  \u001B[38;5;66;03m# Drop any NaN values for safety\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# Calculate match statistics\u001B[39;00m\n\u001B[0;32m---> 47\u001B[0m found_count, total_count, percentage_found \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_match_percentage\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnames\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;66;03m# Print results\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChecked \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_count\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m unique entities.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[0;32mIn[12], line 33\u001B[0m, in \u001B[0;36mcalculate_match_percentage\u001B[0;34m(names)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124;03mCalculate the percentage of names found in Wikidata.\u001B[39;00m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     32\u001B[0m unique_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(names)  \u001B[38;5;66;03m# Ensure uniqueness\u001B[39;00m\n\u001B[0;32m---> 33\u001B[0m matches \u001B[38;5;241m=\u001B[39m [check_wikidata_entry(name) \u001B[38;5;28;01mfor\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtqdm\u001B[49m(unique_names, desc\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mChecking Wikidata\u001B[39m\u001B[38;5;124m\"\u001B[39m)]\n\u001B[1;32m     35\u001B[0m found_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msum\u001B[39m(matches)\n\u001B[1;32m     36\u001B[0m total_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(unique_names)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'tqdm' is not defined"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"\"\"\n",
    "* Exemplary Llama pipeline\n",
    "\"\"\"\n",
    "\n",
    "# Example query with better generation parameters\n",
    "prompt = \"Quantum Mechanics is a topic inside Physics which deals with\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = llama_model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=100,\n",
    "    pad_token_id=tokenizer.eos_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    ")\n",
    "\n",
    "# Decode and print the response\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
   ],
   "id": "607a62f6e41f9261"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
