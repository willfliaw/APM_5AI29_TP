{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17cd0a68",
   "metadata": {},
   "source": [
    "# Knowledge Graph Completion\n",
    "\n",
    "Knowledge Graph Completion (KGC) is the process of enhancing or enriching a knowledge graph by predicting and filling in missing information (links or nodes). A knowledge graph represents relationships between entities in the form of a graph, where entities are nodes and relationships are edges. However, real-world knowledge graphs are often incomplete, with many potential links missing. KGC aims to infer these missing links or facts by leveraging existing data and patterns in the graph.\n",
    "\n",
    "### Key Concepts:\n",
    "\n",
    "-   Entities: Represent real-world objects (e.g., people, places, organizations).\n",
    "-   Relations: The connections between entities (e.g., \"works_for\", \"located_in\").\n",
    "-   Triples: The fundamental unit of a knowledge graph, typically in the form of $(h, r, t)$, where:\n",
    "    -   $ h $ (head) is the starting entity.\n",
    "    -   $ r $ (relation) describes the type of connection.\n",
    "    -   $ t $ (tail) is the target entity.\n",
    "    -   Example: $(\\text{Einstein}, \\text{invented}, \\text{Theory of Relativity})$.\n",
    "\n",
    "### Example of Completion:\n",
    "\n",
    "Given a knowledge graph with the triple:\n",
    "\n",
    "-   $(\\text{Paris}, \\text{capital\\_of}, ?)$\n",
    "\n",
    "    KGC would predict that the missing entity is \"France.\"\n",
    "\n",
    "### Techniques for Knowledge Graph Completion:\n",
    "\n",
    "1. Embedding-Based Methods:\n",
    "    - Translate entities and relations into a continuous vector space.\n",
    "    - Models: TransE, TransH, DistMult, ComplEx.\n",
    "2. Rule-Based Approaches:\n",
    "    - Learn logical rules from the graph to infer missing links.\n",
    "    - Example: If $A \\rightarrow B$ and $B \\rightarrow C$, then $A \\rightarrow C$.\n",
    "3. Graph Neural Networks (GNNs):\n",
    "    - Leverage neural networks to learn from the graph structure.\n",
    "4. Probabilistic Models:\n",
    "    - Predict links based on statistical and probabilistic relationships.\n",
    "5. Neuro-symbolic Approaches:\n",
    "    - Combine symbolic reasoning with neural networks for better interpretability.\n",
    "6. Large Language Models (LLMs):\n",
    "    - Use LLMs to extract triples from text or predict missing relations directly.\n",
    "    - Techniques: Fine-tuning on graph data, prompt-based triple prediction, embedding extraction.\n",
    "\n",
    "### Applications of KGC:\n",
    "\n",
    "-   Recommendation Systems: Predict user preferences by completing user-item interaction graphs.\n",
    "-   Healthcare: Fill missing links in biomedical knowledge graphs for drug discovery.\n",
    "-   Search Engines: Enhance search capabilities by improving knowledge graph coverage.\n",
    "-   Finance: Predict links between entities for fraud detection or market analysis.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db242ba",
   "metadata": {},
   "source": [
    "# PyKEEN and Neo4j for multi-class link prediction using knowledge graph embedding models\n",
    "\n",
    "This notebook demonstrates how to perform knowledge graph completion, focusing on multi-class link prediction. Unlike standard link prediction, which predicts the existence of a link, multi-class link prediction also classifies the type of relationship between entities.\n",
    "\n",
    "To apply this method, the knowledge graph must contain multiple relationship types. If the graph has only one type of relationship, standard [link prediction techniques](https://towardsdatascience.com/a-deep-dive-into-neo4j-link-prediction-pipeline-and-fastrp-embedding-algorithm-bf244aeed50d) or alternative approaches that do not require relationship classification may be more suitable.\n",
    "\n",
    "For multi-class link prediction, we employ knowledge graph embedding models rather than traditional node embedding models. The key distinction lies in their scope:\n",
    "\n",
    "-   Node embedding models generate embeddings solely for nodes.\n",
    "-   Knowledge graph embedding models create embeddings for both nodes and relationships.\n",
    "\n",
    "In knowledge graph embedding, the conventional notation is:\n",
    "\n",
    "-   $h$ – head (starting node)\n",
    "-   $r$ – relationship (edge)\n",
    "-   $t$ – tail (target node)\n",
    "\n",
    "The core idea is that if a relationship exists between nodes, the embedding of the head node ($h$) plus the embedding of the relationship ($r$) should approximate the embedding of the tail node ($t$): $h + r \\approx t$\n",
    "\n",
    "Prediction follows intuitively from this principle. To infer new relationships for a node, sum the node’s embedding with the embedding of a candidate relationship, then evaluate which nodes are closest to the result in the embedding space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f520e31e",
   "metadata": {},
   "source": [
    "# Neo4j Desktop\n",
    "\n",
    "To follow along with this notebook, ensure that the Neo4j Desktop application is installed.\n",
    "\n",
    "Neo4j is a leading graph database platform designed to efficiently store, manage, and query data that is highly interconnected. Unlike traditional relational databases, Neo4j uses a property graph model where data is represented as nodes (entities), edges (relationships), and properties (attributes). This structure makes Neo4j particularly well-suited for applications involving complex relationships, such as knowledge graphs, social networks, fraud detection, and recommendation systems.\n",
    "\n",
    "Key Features of Neo4j:\n",
    "\n",
    "-   Native Graph Storage and Processing – Optimized for handling graph data directly.\n",
    "-   Cypher Query Language – A powerful, declarative language designed for graph traversal and pattern matching.\n",
    "-   Scalability and Performance – Handles large-scale data while maintaining high performance for complex queries.\n",
    "-   Visualization Tools – Enables intuitive visualization of graph structures and relationships.\n",
    "-   Extensibility – Supports integration with various tools, plugins, and programming languages.\n",
    "\n",
    "After installing Neo4j Desktop, download a database dump and restore it to create a database instance. For this demonstration, you can use a [subset of the Hetionet](https://drive.google.com/file/d/1u34cFBYvBtdBsqOUPdmbcIyIt88IiZYe/view?usp=sharing), a knowledge graph containing information on genes, compounds, and diseases. This dataset includes numerous relationships between entities, primarily within the biomedical domain. While a deep understanding of these relationships may require domain expertise, we will focus on the treats relationship, which links compounds to diseases.\n",
    "\n",
    "In this notebook, we will apply knowledge graph embedding models to predict new treats relationships, simulating a drug repurposing task – identifying potential new uses for existing drugs based on inferred connections within the graph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3beed",
   "metadata": {},
   "source": [
    "# PyKEEN\n",
    "\n",
    "[PyKEEN](https://pykeen.readthedocs.io/en/stable/index.html) (Python Knowledge Embedding Engine) is an open-source Python library for training and evaluating knowledge graph embedding (KGE) models. It simplifies the application of machine learning to knowledge graphs by providing pre-implemented models, training pipelines, and evaluation tools.  \n",
    "\n",
    "## Key Features:  \n",
    "\n",
    "- Model Support: Includes models like TransE, DistMult, ComplEx, and RotatE.  \n",
    "- Modular and Customizable: Easily mix, match, and extend components.  \n",
    "- Automation: Handles hyperparameter tuning, training, and evaluation.  \n",
    "- Benchmarking: Compares model performance across datasets.  \n",
    "- Visualization: Offers tools to analyze embeddings and results.  \n",
    "\n",
    "## Use Cases:  \n",
    "\n",
    "- Knowledge Graph Completion: Predict missing links and relationship types.  \n",
    "- Link Prediction: Identify potential connections between entities.  \n",
    "- Node Classification: Infer properties or classes for nodes.  \n",
    "- Recommender Systems: Suggest related items by predicting links.  \n",
    "- Biomedical and NLP Applications: Predict interactions, enhance search, and retrieve information.  \n",
    "\n",
    "PyKEEN is widely used in fields like healthcare, social networks, and recommendation systems for knowledge graph analysis and enrichment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a276429b",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5d5e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from neo4j import GraphDatabase\n",
    "from pykeen import predict\n",
    "from pykeen.pipeline import pipeline\n",
    "from pykeen.triples import TriplesFactory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facd1844",
   "metadata": {},
   "source": [
    "# Hyperparameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f9cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Neo4j connections\n",
    "host = \"bolt://localhost:7687\"\n",
    "user = \"neo4j\"\n",
    "password = \"123456798\"\n",
    "driver = GraphDatabase.driver(host, auth=(user, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07fcb99",
   "metadata": {},
   "source": [
    "# Auxiliary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9a1139",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query, params={}):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, params)\n",
    "        return pd.DataFrame([r.values() for r in result], columns=result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67980348",
   "metadata": {},
   "source": [
    "# Transform a Neo4j to a PyKEEN\n",
    "\n",
    "Now we will move on to the practical part of this post.\n",
    "First, we will transform the Neo4j graph to the PyKEEN graph and split the train-test data. To begin, we have to define the connection to the Neo4j database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079ff947",
   "metadata": {},
   "source": [
    "The `run_query` function executes a Cypher query and returns the output in the form of a Pandas dataframe. The PyKEEN library has a `from_labeled_triples` that takes a list of triples as an input and constructs a graph from it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562a480b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = run_query(\n",
    "    \"\"\"\n",
    "    MATCH (s)-[r]->(t)\n",
    "    RETURN toString(id(s)) as source, toString(id(t)) AS target, type(r) as type\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dcda05",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "045f9596",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TriplesFactory.from_labeled_triples(\n",
    "    data[[\"source\", \"type\", \"target\"]].values,\n",
    "    create_inverse_triples=False,\n",
    "    entity_to_id=None,\n",
    "    relation_to_id=None,\n",
    "    compact_id=False,\n",
    "    filter_out_candidate_inverse_relations=True,\n",
    "    metadata=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424bd14",
   "metadata": {},
   "source": [
    "This example has a generic Cypher query that can be used to fetch any Neo4j dataset and construct a PyKEEN from it. Notice that we use the internal Neo4j ids of nodes to build the triples data frame. For some reason, the PyKEEN library expects the triple elements to be all strings, so we simply cast the internal ids to string. Now that we have our PyKEEN graph, we can use the split method to perform the train-test data split.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d77b130",
   "metadata": {},
   "outputs": [],
   "source": [
    "training, testing, validation = tf.split([0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcdfcf6",
   "metadata": {},
   "source": [
    "# Train a knowledge graph embedding model\n",
    "\n",
    "Now that we have the train-test data available, we can go ahead and train a knowledge graph embedding model. We will use the RotatE model in this example. I am not that familiar with all the variations of the embedding models, but if you want to learn more, I would suggest the lecture by Jure Leskovec I linked above.\n",
    "We won't perform any hyper-parameter optimization to keep the tutorial simple. I've chosen to use 20 epochs and defined the dimension size to be 512.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47868ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline(\n",
    "    training=training,\n",
    "    testing=testing,\n",
    "    validation=validation,\n",
    "    model=\"RotatE\",\n",
    "    stopper=\"early\",\n",
    "    epochs=20,\n",
    "    dimensions=512,\n",
    "    random_seed=420,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01aecd6",
   "metadata": {},
   "source": [
    "# Multi-class link prediction\n",
    "\n",
    "The PyKEEN library supports multiple methods for multi-class link prediction.\n",
    "You could find the top K predictions in the network, or you can be more specific and define a particular head node and relationship type and evaluate if there are any new connections predicted.\n",
    "\n",
    "In this example, you will predict new treats relationships for the L-Asparagine compound. Because we used the internal node ids for mapping, we first have to retrieve the node id of L-Asparagine from Neo4j and input it into the prediction method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f870831",
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_id = run_query(\n",
    "    \"\"\"\n",
    "    MATCH (s:Compound)\n",
    "    WHERE s.name = \"L-Asparagine\"\n",
    "    RETURN toString(id(s)) as id\n",
    "    \"\"\"\n",
    ")[\"id\"][0]\n",
    "\n",
    "\n",
    "df = predict.predict_target(\n",
    "    result.model, compound_id, \"treats\", triples_factory=result.training\n",
    ").df\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94d0907",
   "metadata": {},
   "source": [
    "# Store predictions to Neo4j\n",
    "\n",
    "For easier evaluation of the results, we will store the top five predictions back to Neo4j.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb6e1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_nodes = df[df[\"in_training\"] == False].head(5)[\"tail_label\"].to_list()\n",
    "\n",
    "run_query(\n",
    "    \"\"\"\n",
    "    MATCH (n)\n",
    "    WHERE id(n) = toInteger($compound_id)\n",
    "    UNWIND $candidates as ca\n",
    "    MATCH (c)\n",
    "    WHERE id(c) = toInteger(ca)\n",
    "    MERGE (n)-[:PREDICTED_TREATS]->(c)\n",
    "    \"\"\",\n",
    "    {\"compound_id\": compound_id, \"candidates\": candidate_nodes},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53963721",
   "metadata": {},
   "source": [
    "# Inspect results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bee3736",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_query(\n",
    "    \"\"\"\n",
    "    MATCH (c:Compound)-[:PREDICTED_TREATS]->(d:Disease)\n",
    "    RETURN c.name as compound, d.name as disease\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2483793b",
   "metadata": {},
   "source": [
    "# Explaining predictions\n",
    "\n",
    "As far as I know, the knowledge graph embedding model is not that useful for explaining predictions. On the other hand, you could use the existing connections in the graph to present the information to a medical doctor and let him decide if the predictions make sense or not.\n",
    "For example, you could investigate direct and indirect paths between L-Asparagine and colon cancer with the following Cypher query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6455bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_query(\n",
    "    \"\"\"\n",
    "    MATCH (c:Compound {name: \"L-Asparagine\"}),(d:Disease {name:\"colon cancer\"})\n",
    "    WITH c,d\n",
    "    MATCH p=AllShortestPaths((c)-[r:binds|regulates|interacts|upregulates|downregulates|associates*1..4]-(d))\n",
    "    RETURN [n in nodes(p) | n.name] LIMIT 25\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329cd10b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-structured",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
